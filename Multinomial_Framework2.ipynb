{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67638b84-6a1c-4cbe-a123-abc41f20ff2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Multinomial_Framework2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Multinomial_Framework2.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.ensemble import RandomForestClassifier as SklearnRFC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import Union, Tuple\n",
    "\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        # self.X = torch.tensor(X, dtype = torch.float32).to(device)\n",
    "        # self.Y = torch.tensor(Y, dtype = torch.long).to(device)\n",
    "        self.X = torch.tensor(X.values if hasattr(X, 'values') else X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y.values if hasattr(Y, 'values') else Y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.Y[index]\n",
    "\n",
    "class RandomForestWrapper():\n",
    "    '''Wrapper for sklearn's RandomForestClassifier with consistent API.'''\n",
    "\n",
    "    def __init__(self, n_estimators=200, max_depth=None, min_samples_split=2,\n",
    "                 class_weight='balanced', random_state=42, n_jobs=-1):\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.class_weight = class_weight\n",
    "        self.random_state = random_state\n",
    "        self.n_jobs = n_jobs\n",
    "        \n",
    "        self.model = SklearnRFC(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            class_weight=class_weight,\n",
    "            random_state=random_state,\n",
    "            n_jobs=n_jobs\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        acc = accuracy_score(y, preds)\n",
    "        return {\"accuracy\": round(acc*100,3)}\n",
    "\n",
    "class NN_Wrapper():\n",
    "    '''Wrapper for PyTorch neural networks with the same interface as sklearn models.'''\n",
    "    \n",
    "    def __init__(self, model: nn.Module, criterion, optimizer: torch.optim.Optimizer,\n",
    "                 epochs: int = 10, batch_size: int = 256, device: str = None):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        total_acc_train_plot = []\n",
    "        X_tensor = torch.tensor(X.values if hasattr(X, 'values') else X, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y.values if hasattr(y, 'values') else y, dtype=torch.long)\n",
    "        dataset = TensorDataset(X_tensor, y_tensor)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                preds = self.model(inputs)     \n",
    "                \n",
    "                loss = self.criterion(preds, labels)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                predicted_classes = torch.argmax(preds,dim=1)\n",
    "                \n",
    "                acc = (predicted_classes == labels).sum().item()\n",
    "\n",
    "                total_acc += acc\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                self.optimizer.step()\n",
    "                \n",
    "            total_acc_train_plot.append(round(total_acc/X.__len__() * 100, 4))    \n",
    "            print(f\"Epoch [{epoch+1}/{self.epochs}] | Loss: {round(total_loss/len(dataloader) * 100, 4)} | Train Acc: {round(total_acc/X.__len__() * 100, 4)}\")\n",
    "        return self, total_acc_train_plot\n",
    "\n",
    "    def predict(self, testing_dataloader):\n",
    "        #X_tensor = torch.tensor(X.values if hasattr(X, 'values') else X, dtype=torch.float32)\n",
    "        #self.model.eval()\n",
    "        total_loss_test = 0\n",
    "        total_acc_test = 0\n",
    "        total_acc_test_plot = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testing_dataloader:\n",
    "                preds = self.model(inputs)\n",
    "                loss = self.criterion(preds,labels)\n",
    "                total_loss_test += loss\n",
    "                predicted_classes = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "                acc = (predicted_classes == labels).sum().item()\n",
    "                total_acc_test += acc\n",
    "                total_acc_test_plot.append(round(total_acc_test/len(testing_dataloader.dataset) * 100, 4)) \n",
    "        test_size = len(testing_dataloader.dataset)\n",
    "        avg_acc = total_acc_test / test_size\n",
    "        avg_loss = total_loss_test / len(testing_dataloader)\n",
    "        \n",
    "        print(f'Test Accuracy: {avg_acc*100:.2f}% | Test Loss: {avg_loss*100:.2f}')\n",
    "        return total_acc_test_plot\n",
    "\n",
    "class Diabetes_Predictor_NN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes=3, hidden_neurons=3):\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_neurons),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(hidden_neurons,32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(16,num_classes),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.linear_layer_stack(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bba90a-abc9-4e74-946d-9abb962445eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
